{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Libraries\n",
    "###############\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogenize_columns(dirname, destination):\n",
    "    \"\"\" \n",
    "    homogenize_columns. \n",
    "  \n",
    "    Set the same estructure of columns for all the data frames. \n",
    "  \n",
    "    Parameters: \n",
    "    dirname (str)     : Directory to extract and change the colum names \n",
    "    destination (str) : Directory where the new data sets will save\n",
    "      \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    DF_list= list()\n",
    "    \n",
    "    for filename in sorted(glob.glob(dirname + '/*.csv')):\n",
    "        #print(filename)\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        #Rename all columns \n",
    "        #df = df.rename(columns={  \"Entidad\"          : \"Entidad\",\n",
    "        #                          \"Municipio\"        : \"Municipio\",\n",
    "        #                         \"No de \\nMuertos\"  : \"Homicidios\",\n",
    "        #                          \"No. de \\nmuertos\" : \"Homicidios\",\n",
    "        #                          \"Hombre\"           : \"Hombre\",\n",
    "        #                          \"Mujer\"            : \"Mujer\",\n",
    "        #                          \"No \\nIdentificado\": \"No Identificado\"})\n",
    "        \n",
    "        df = df.rename(columns={ \n",
    "                          df.columns[0]: \"Entidad\",\n",
    "                          df.columns[1]: \"Municipio\", \n",
    "                          df.columns[2]: \"Homicidios\",\n",
    "                          df.columns[3]: \"Hombre\",\n",
    "                          df.columns[4]: \"Mujer\",\n",
    "                          df.columns[5]: \"No Identificado\",\n",
    "\n",
    "                          \n",
    "                          \n",
    "                         })\n",
    "        ##Just for January 2019##\n",
    "        ##Comment if month != January\n",
    "        #df[\"Hombre\"] = np.nan\n",
    "        #df[\"Mujer\"] = np.nan\n",
    "        #df[\"No Identificado\"] = np.nan\n",
    "\n",
    "\n",
    "        path = Path(filename).stem\n",
    "        print(path)\n",
    "\n",
    "        #print(df)\n",
    "        df.to_csv( destination  + path + \".csv\",encoding=\"utf-8\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01082020\n",
      "02082020\n",
      "03082020\n",
      "04082020\n",
      "05082020\n",
      "06082020\n",
      "07082020\n",
      "08082020\n",
      "09082020\n",
      "10082020\n",
      "11082020\n",
      "12082020\n",
      "13082020\n",
      "14082020\n",
      "15082020\n",
      "16082020\n"
     ]
    }
   ],
   "source": [
    "homogenize_columns(\"/Users/marianafernandez/Desktop/AugustTest\",\"/Users/marianafernandez/Desktop/AugustTest/\" )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove row \"Total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_row_totales(dirname):\n",
    "    \"\"\" \n",
    "    drop_row_totales. \n",
    "  \n",
    "    Remove all rows with the string \"Totales\"\n",
    "  \n",
    "    Parameters: \n",
    "    dirname (str)     : Directory to extract and change the colum names       \n",
    "\n",
    "    \"\"\"\n",
    "    for filename in sorted(glob.glob(dirname + '/*.csv')):\n",
    "        df = pd.read_csv(filename)\n",
    "    \n",
    "\n",
    "        path = Path(filename).stem\n",
    "        print(path)\n",
    "        df = df.drop(df[df.Entidad == \"Totales\"].index)\n",
    "        \n",
    "        df.to_csv( dirname  + path + \".csv\",encoding=\"utf-8\", index = False)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01082020\n",
      "02082020\n",
      "03082020\n",
      "04082020\n",
      "05082020\n",
      "06082020\n",
      "07082020\n",
      "08082020\n",
      "09082020\n",
      "10082020\n",
      "11082020\n",
      "12082020\n",
      "13082020\n",
      "14082020\n",
      "15082020\n",
      "16082020\n"
     ]
    }
   ],
   "source": [
    "#drop_row_totales(\"../data_raw/county/2020/March/\")\n",
    "drop_row_totales(\"/Users/marianafernandez/Desktop/AugustTest/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean digits and characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_digits_scha(dirname):\n",
    "    \"\"\"\n",
    "    clean_digits_str.\n",
    "    \n",
    "    Clean digits and special characters '()' of column \"Entidad\"\n",
    "    \n",
    "    Parameters: \n",
    "    \n",
    "    dirname (str)     : Directory to extract and change the colum names \n",
    "    destination (str) : Directory where the new data sets will save\n",
    "    \n",
    "    \"\"\"\n",
    "    for filename in sorted(glob.glob(dirname + '/*.csv')):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "        path = Path(filename).stem\n",
    "        print(path)\n",
    "\n",
    "        #Replace values NaN with the value of last string\n",
    "        df = df.fillna(method ='pad') \n",
    "\n",
    "        df['Entidad']=df['Entidad'].apply(str)\n",
    "        df[\"Entidad\"] = df[\"Entidad\"].apply(lambda x: re.sub('[()]', '', x))\n",
    "        df[\"Entidad\"] = df[\"Entidad\"].apply(lambda x: re.sub('[\"\\b\\d+\\b\"]', '', x))\n",
    "        \n",
    "        df.to_csv( dirname  + path + \".csv\",encoding=\"utf-8\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01082020\n",
      "02082020\n",
      "03082020\n",
      "04082020\n",
      "05082020\n",
      "06082020\n",
      "07082020\n",
      "08082020\n",
      "09082020\n",
      "10082020\n",
      "11082020\n",
      "12082020\n",
      "13082020\n",
      "14082020\n",
      "15082020\n",
      "16082020\n"
     ]
    }
   ],
   "source": [
    "#clean_digits_scha(\"../data_raw/county/2020/August/\")\n",
    "clean_digits_scha(\"/Users/marianafernandez/Desktop/AugustTest/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group States and Counties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_states_counties(dirname):\n",
    "    \"\"\"\n",
    "   group_states_counties\n",
    "    \n",
    "    Group by Entidad and Municipio and sum values\n",
    "    \n",
    "    Parameters: \n",
    "    \n",
    "    dirname (str)     : Directory to extract and overwrite the new data frames \n",
    "    \n",
    "    \"\"\"\n",
    "    for filename in sorted(glob.glob(dirname + '/*.csv')):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        #Just for January\n",
    "        #df = df.groupby(['Entidad',\"Municipio\"]).agg('sum')\n",
    "        #df =df.reset_index()\n",
    "        \n",
    "        df[['Homicidios',\n",
    "             'Hombre',\n",
    "             'Mujer',\n",
    "             'No Identificado']] = df[['Homicidios',\n",
    "                                         'Hombre',\n",
    "                                         'Mujer',\n",
    "                                         'No Identificado']].apply(pd.to_numeric,errors = 'coerce')\n",
    "        \n",
    "        df = df.groupby(['Entidad',\"Municipio\"]).sum().reset_index()\n",
    "        \n",
    "        path = Path(filename).stem\n",
    "        print(path)\n",
    "        \n",
    "        df.to_csv( dirname  + path + \".csv\",encoding=\"utf-8\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01082020\n",
      "02082020\n",
      "03082020\n",
      "04082020\n",
      "05082020\n",
      "06082020\n",
      "07082020\n",
      "08082020\n",
      "09082020\n",
      "10082020\n",
      "11082020\n",
      "12082020\n",
      "13082020\n",
      "14082020\n",
      "15082020\n",
      "16082020\n"
     ]
    }
   ],
   "source": [
    "#group_states_counties(\"../data_raw/county/2020/August/\")\n",
    "group_states_counties(\"/Users/marianafernandez/Desktop/AugustTest/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for January\n",
    "\n",
    "def complete_columns(dirname):\n",
    "    for filename in sorted(glob.glob(dirname + '/*.csv')):\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        df[\"Hombre\"] = np.nan\n",
    "        df[\"Mujer\"] = np.nan\n",
    "        df[\"No identificado\"] = np.nan\n",
    "        \n",
    "        path = Path(filename).stem\n",
    "        print(path)\n",
    "        \n",
    "        df.to_csv( dirname  + path + \".csv\",encoding=\"utf-8\", index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_columns(\"./data-cleaning/county/data-raw/2019-final-version/January/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def checker_counties_name(dirname):\n",
    "    v_correct_states = [  \"Aguascalientes\",\n",
    "                          \"Baja California\",\n",
    "                          \"Baja California Sur\",\n",
    "                          \"Campeche\",\n",
    "                          \"Coahuila\",\n",
    "                          \"Colima\",\n",
    "                          \"Chiapas\",\n",
    "                          \"Chihuahua\",\n",
    "                          \"Ciudad de México\",\n",
    "                          \"Durango\",\n",
    "                          \"Guanajuato\",\n",
    "                          \"Guerrero\",\n",
    "                          \"Hidalgo\",\n",
    "                          \"Jalisco\",\n",
    "                          \"Estado de México\",\n",
    "                          \"Michoacán\",\n",
    "                          \"Morelos\",\n",
    "                          \"Nayarit\",\n",
    "                          \"Nuevo León\",\n",
    "                          \"Oaxaca\",\n",
    "                          \"Puebla\",\n",
    "                          \"Querétaro\",\n",
    "                          \"Quintana Roo\",\n",
    "                          \"San Luis Potosí\",\n",
    "                          \"Sinaloa\",\n",
    "                          \"Sonora\",\n",
    "                          \"Tabasco\",\n",
    "                          \"Tamaulipas\",\n",
    "                          \"Tlaxcala\",\n",
    "                          \"Veracruz\",\n",
    "                          \"Yucatán\",\n",
    "                          \"Zacatecas\"\n",
    "                       ]\n",
    "    col_list = [\"Entidad\", \"Municipio\"]\n",
    "    \n",
    "    for filename in sorted(glob.glob(dirname + '/*.csv')):\n",
    "        df = pd.read_csv(filename, usecols=col_list)\n",
    "        print(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker_counties_name(\"./data-cleaning/county/data-raw/2019-final-version/January/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explore Directories\n",
    "dirname = \"./data-cleaning/county/data-raw/2019-cleanVersion/January/\"\n",
    "directory = \"./data-cleaning/county/data-raw/2019-cleanVersion2/\"\n",
    "DF_list= list()\n",
    "\n",
    "for filename in sorted(glob.glob(dirname + '/*.csv')):\n",
    "    #print(filename)\n",
    "    df7 = pd.read_csv(filename)\n",
    "    \n",
    "    #Rename all columns\n",
    "    df7 = df7.rename(columns={\"Entidad\": \"Entidad\",\n",
    "                              \"Municipio\" : \"Municipio\",\n",
    "                              \"No de \\nMuertos\": \"Homicidios\",\n",
    "                              \"No. de \\nmuertos\": \"Homicidios\",\n",
    "                               \"Hombre\": \"Hombre\",\n",
    "                                 \"Mujer\": \"Mujer\",\n",
    "                             \"No \\nIdentificado\": \"No Identificado\"})\n",
    "    #df7['Entidad']=df7['Entidad'].apply(str)\n",
    "    df7[\"Entidad\"] = df7[\"Entidad\"].apply(lambda x: re.sub('[()]', '', x))\n",
    "    #df7[\"Entidad\"] = df7[\"Entidad\"].apply(lambda x: re.sub('[\"\\b\\d+\\b\"]', '', x))\n",
    "    \n",
    "    #x =df7['Entidad'].isna()\n",
    "    print(x)\n",
    "    #df7[\"Entidad\"] = df7.fillna(method ='pad') \n",
    "    #path = Path(filename).stem\n",
    "    #print(path)\n",
    "\n",
    "    #print(df7)\n",
    "    #df7.to_csv( directory  + path + \".csv\",encoding=\"utf-8\", index = False)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/Users/marianafernandez/Documents/PADeCI/homicidios-mx/data-cleaning/county/data-raw/2019-final-version/January/homicidios_01012019.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(df1[df1.Entidad == \"Totales\"].index)\n",
    "\n",
    "df1 = df1.replace(\"-\", 0)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "#df1['Entidad']=df1['Entidad'].apply(str)\n",
    "#df1['Entidad'] = df1['Entidad'].replace(['nan'],'NaN')\n",
    "df1 = df1.fillna(method ='pad') \n",
    "\n",
    "df1\n",
    "df1['Entidad']=df1['Entidad'].apply(str)\n",
    "df1[\"Entidad\"] = df1[\"Entidad\"].apply(lambda x: re.sub('[()]', '', x))\n",
    "df1[\"Entidad\"] = df1[\"Entidad\"].apply(lambda x: re.sub('[\"\\b\\d+\\b\"]', '', x))\n",
    "\n",
    "#Sum entidad y municipio\n",
    "\n",
    "\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.groupby(['Entidad',\"Municipio\", \"Hombre\", \"Mujer\", \"No \\nIdentificado\"]).agg('sum')\n",
    "#df1 =df1.reset_index()\n",
    "#df1    \n",
    "\n",
    "df1[['No de \\nMuertos','Hombre','Mujer','No \\nIdentificado']]=df1[['No de \\nMuertos','Hombre','Mujer','No \\nIdentificado']].apply(pd.to_numeric,errors = 'coerce')\n",
    "df1 = df1.groupby(['Entidad',\"Municipio\"]).sum().reset_index()\n",
    "#df1.groupby([\"Entidad\",'Municipio']).agg('sum')\n",
    "# \"No de \\nMuertos\", \"Hombre\", \"Mujer\", \"No \\nIdentificado\"\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Hombres\"] = np.nan\n",
    "df1[\"Mujeres\"] = np.nan\n",
    "df1[\"No identificado\"] = np.nan\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
